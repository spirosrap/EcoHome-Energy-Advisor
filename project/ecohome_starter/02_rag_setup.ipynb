{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EcoHome Energy Advisor - RAG Setup\n",
        "\n",
        "In this notebook, you'll set up the Retrieval-Augmented Generation (RAG) pipeline for the EcoHome Energy Advisor. This will allow the agent to access and cite relevant energy-saving tips and best practices.\n",
        "\n",
        "## Learning Objectives\n",
        "- Set up ChromaDB vector store\n",
        "- Load and process energy-saving documents\n",
        "- Create embeddings for document chunks\n",
        "- Implement semantic search functionality\n",
        "- Test the RAG pipeline\n",
        "\n",
        "## Documents Available\n",
        "- `tip_device_best_practices.txt` - Device-specific optimization tips\n",
        "- `tip_energy_savings.txt` - General energy-saving strategies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the necessary libraries for RAG setup\n",
        "import os\n",
        "from langchain_chroma  import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Process Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the energy-saving tip documents\n",
        "# Load both tip_device_best_practices.txt and tip_energy_savings.txt\n",
        "# Use TextLoader to load the documents\n",
        "\n",
        "documents = []\n",
        "document_paths = [\n",
        "    \"data/documents/tip_device_best_practices.txt\",\n",
        "    \"data/documents/tip_energy_savings.txt\"\n",
        "]\n",
        "\n",
        "for doc_path in document_paths:\n",
        "    if os.path.exists(doc_path):\n",
        "        loader = TextLoader(doc_path)\n",
        "        docs = loader.load()\n",
        "        documents.extend(docs)\n",
        "        print(f\"Loaded {len(docs)} documents from {doc_path}\")\n",
        "    else:\n",
        "        print(f\"Warning: {doc_path} not found\")\n",
        "\n",
        "print(f\"Total documents loaded: {len(documents)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Split Documents into Chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split documents into smaller chunks for better retrieval\n",
        "# Use RecursiveCharacterTextSplitter with appropriate chunk_size and chunk_overlap\n",
        "# Experiment with different chunk sizes (e.g., 500, 1000, 1500 characters)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "# Split the documents\n",
        "splits = text_splitter.split_documents(documents)\n",
        "print(f\"Split {len(documents)} documents into {len(splits)} chunks\")\n",
        "\n",
        "# Show sample chunk\n",
        "if splits:\n",
        "    print(f\"\\nSample chunk (first 200 characters):\")\n",
        "    print(splits[0].page_content[:200] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Vector Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a ChromaDB vector store\n",
        "# Initialize OpenAIEmbeddings\n",
        "# Create the vector store with the document chunks\n",
        "# Persist the vector store to disk for future use\n",
        "\n",
        "# Set up the persist directory\n",
        "persist_directory = \"data/vectorstore\"\n",
        "os.makedirs(persist_directory, exist_ok=True)\n",
        "\n",
        "# Initialize embeddings\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    base_url=\"https://openai.vocareum.com/v1\",\n",
        "    api_key=os.getenv(\"VOCAREUM_API_KEY\")\n",
        ")\n",
        "\n",
        "# Create the vector store\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "print(f\"Vector store created and persisted to {persist_directory}\")\n",
        "print(f\"Total vectors stored: {len(splits)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test the RAG Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the search functionality\n",
        "# Try different queries related to energy optimization\n",
        "# Test queries like:\n",
        "# - \"electric vehicle charging tips\"\n",
        "# - \"thermostat optimization\"\n",
        "# - \"dishwasher energy saving\"\n",
        "# - \"solar power maximization\"\n",
        "\n",
        "test_queries = [\n",
        "    \"electric vehicle charging tips\",\n",
        "    \"thermostat optimization\",\n",
        "    \"dishwasher energy saving\",\n",
        "    \"solar power maximization\",\n",
        "    \"HVAC system efficiency\",\n",
        "    \"pool pump scheduling\"\n",
        "]\n",
        "\n",
        "print(\"=== Testing Vector Search ===\")\n",
        "for query in test_queries:\n",
        "    print(f\"\\nQuery: '{query}'\")\n",
        "    docs = vectorstore.similarity_search(query, k=2)\n",
        "    for i, doc in enumerate(docs):\n",
        "        print(f\"  Result {i+1}: {doc.page_content[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test the Search Tool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the search_energy_tips tool from tools.py\n",
        "# Import and test the tool with various queries\n",
        "# Verify that it returns relevant results\n",
        "\n",
        "from tools import search_energy_tips\n",
        "\n",
        "# Test the search_energy_tips function\n",
        "print(\"=== Testing search_energy_tips Tool ===\")\n",
        "\n",
        "test_queries = [\n",
        "    \"electric vehicle charging\",\n",
        "    \"thermostat settings\",\n",
        "    \"dishwasher optimization\",\n",
        "    \"solar power tips\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\nQuery: '{query}'\")\n",
        "    result = search_energy_tips.invoke(\n",
        "        input={\n",
        "            \"query\": query, \n",
        "            \"max_results\": 3,\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    if \"error\" in result:\n",
        "        print(f\"  Error: {result['error']}\")\n",
        "    else:\n",
        "        print(f\"  Found {result['total_results']} results\")\n",
        "        for i, tip in enumerate(result['tips']):\n",
        "            print(f\"    {i+1}. {tip['content'][:100]}...\")\n",
        "            print(f\"       Source: {tip['source']}\")\n",
        "            print(f\"       Relevance: {tip['relevance_score']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cd14640 (3.11.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
